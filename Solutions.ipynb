{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 0:\n",
      "Values: [0. 0. 0. 0. 0. 0.]\n",
      "Policy: [0 0 0 0 0 0]\n",
      "Value per step: [0. 0. 0. 0. 0. 0.]\n",
      "Time 1:\n",
      "Values: [  0.  25.  25.  25.  25. -10.]\n",
      "Policy: [0 0 0 0 0 0]\n",
      "Value per step: [  0.  25.  25.  25.  25. -10.]\n",
      "Time 2:\n",
      "Values: [ 25.    50.    48.25  43.    32.5  -10.  ]\n",
      "Policy: [0 0 0 0 0 0]\n",
      "Value per step: [25.   25.   23.25 18.    7.5   0.  ]\n",
      "Time 3:\n",
      "Values: [50.    74.825 69.025 56.35  45.    15.   ]\n",
      "Policy: [0 0 0 0 1 0]\n",
      "Value per step: [25.    24.825 20.775 13.35  12.5   25.   ]\n",
      "Time 4:\n",
      "Values: [74.825 99.245 88.855 71.945 69.825 40.   ]\n",
      "Policy: [0 0 0 0 1 0]\n",
      "Value per step: [24.825 24.42  19.83  15.595 24.825 25.   ]\n",
      "Time 5:\n",
      "Values: [ 99.245   123.206   108.76975  92.245    94.245    64.825  ]\n",
      "Policy: [0 0 0 1 1 0]\n",
      "Value per step: [24.42    23.961   19.91475 20.3     24.42    24.825  ]\n",
      "Time 6:\n",
      "Values: [123.206    146.762375 129.1938   116.206    118.206     89.245   ]\n",
      "Policy: [0 0 0 1 1 0]\n",
      "Value per step: [23.961    23.556375 20.42405  23.961    23.961    24.42    ]\n",
      "Iteration 1: delta = 2500.0\n",
      "V = [  0.  25.  25.  25.  25. -10.]\n",
      "Iteration 2: delta = 2500.0\n",
      "V = [ 25.    50.    48.25  43.    32.5  -10.  ]\n",
      "Iteration 3: delta = 0.9992006394884093\n",
      "V = [50.    74.825 69.025 56.35  45.    15.   ]\n",
      "Iteration 4: delta = 0.6026914450496637\n",
      "V = [74.825 99.245 88.855 71.945 69.825 40.   ]\n",
      "Iteration 5: delta = 0.24643972948217693\n",
      "V = [ 99.245   123.206   108.76975  92.245    94.245    64.825  ]\n",
      "Iteration 6: delta = 0.1955535001627182\n",
      "V = [123.206    146.762375 129.1938   116.206    118.206     89.245   ]\n",
      "Iteration 7: delta = 0.13261001143902437\n",
      "V = [146.762375  170.0055175 150.34819   139.762375  141.762375  113.206    ]\n",
      "Iteration 8: delta = 0.08776160389340958\n",
      "V = [170.0055175  193.03978475 172.00320825 163.0055175  165.0055175\n",
      " 136.762375  ]\n",
      "Iteration 9: delta = 0.05704247625836077\n",
      "V = [193.03978475 215.9361271  193.99151298 186.03978475 188.03978475\n",
      " 160.0055175 ]\n",
      "Iteration 10: delta = 0.037191846795296586\n",
      "V = [215.9361271  238.74166569 216.19945397 208.9361271  210.9361271\n",
      " 183.03978475]\n",
      "Iteration 11: delta = 0.024318587600036825\n",
      "V = [238.74166569 261.48744452 238.55197148 231.74166569 233.74166569\n",
      " 205.9361271 ]\n",
      "Iteration 12: delta = 0.01593561591870895\n",
      "V = [261.48744452 284.19389721 260.99963339 254.48744452 256.48744452\n",
      " 228.74166569]\n",
      "Iteration 13: delta = 0.010457490510743322\n",
      "V = [284.19389721 306.87447083 283.50990667 277.19389721 279.19389721\n",
      " 251.48744452]\n",
      "Iteration 14: delta = 0.006869108512131701\n",
      "V = [306.87447083 329.53801441 306.06138215 299.87447083 301.87447083\n",
      " 274.19389721]\n",
      "Optimal Value:\n",
      "[306.87447083 329.53801441 306.06138215 299.87447083 301.87447083\n",
      " 274.19389721]\n",
      "Optimal Policy:\n",
      "[0 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from MDP import *\n",
    "\n",
    "# Define states and actions.\n",
    "num_states = 6\n",
    "states = np.arange(num_states)\n",
    "actions = np.array([0, 1])  # Actions: 0 and 1\n",
    "num_actions = len(actions)\n",
    "P = 25 \n",
    "\n",
    "# Define transition probabilities.\n",
    "Q = np.array([\n",
    "    [0.9, 0.1, 0.0, 0.0, 0.0],   \n",
    "    [0.0, 0.8, 0.1, 0.05, 0.05], \n",
    "    [0.0, 0.0, 0.7, 0.1, 0.2],   \n",
    "    [0.0, 0.0, 0.0, 0.5, 0.5],   \n",
    "])\n",
    "\n",
    "# Initialize the transitions array.\n",
    "transitions = np.zeros((num_states, num_actions, num_states))\n",
    "\n",
    "for s in states:\n",
    "    if s == 0:\n",
    "        # From state 0, any action leads to state 1 with probability 1.0\n",
    "        for a in range(num_actions):\n",
    "            transitions[s, a, 1] = 1.0\n",
    "    elif s == 5:\n",
    "        # From state 5, any action leads to state 0 with probability 1.0\n",
    "        for a in range(num_actions):\n",
    "            transitions[s, a, 0] = 1.0\n",
    "    else:\n",
    "        for a in range(num_actions):\n",
    "            if a == 0:\n",
    "                # Action 0: transitions defined by Q\n",
    "                transitions[s, a, 1:6] = Q[s-1]\n",
    "            else:\n",
    "                # Action 1: transitions to state 1 with probability 1.0\n",
    "                transitions[s, a, 1] = 1.0\n",
    "\n",
    "# Define rewards.\n",
    "rewards = np.zeros((num_states, num_actions))\n",
    "c_p = [0, 7, 7, 5]  # Rewards for action 1 in states 1 to 4\n",
    "\n",
    "for s in states:\n",
    "    for a in range(num_actions):\n",
    "        if s == 0:\n",
    "            rewards[s, a] = 0\n",
    "        elif s == 5:\n",
    "            rewards[s, a] = -10\n",
    "        elif a == 0:\n",
    "            rewards[s, a] = P\n",
    "        elif a == 1:\n",
    "            rewards[s, a] = -c_p[s-1]\n",
    "\n",
    "# Set the time horizon.\n",
    "horizon = 7\n",
    "\n",
    "# Initialize and solve the MDP.\n",
    "mdp = FiniteHorizonMDP(num_states, num_actions, transitions, rewards, horizon)\n",
    "V, policy, dV = mdp.solve()\n",
    "\n",
    "# Print the results.\n",
    "for t in range(horizon):\n",
    "    print(f\"Time {t}:\")\n",
    "    print(\"Values:\", V[t])\n",
    "    print(\"Policy:\", policy[t])\n",
    "    print(\"Value per step:\", dV[t])\n",
    "\n",
    "ihmdp = InfiniteHorizonMDP(num_states, num_actions, transitions, rewards)\n",
    "V_v, policy_v = ihmdp.value_iteration()\n",
    "print(\"Optimal Value:\")\n",
    "print(V_v)\n",
    "print(\"Optimal Policy:\")\n",
    "print(policy_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 0:\n",
      "Values: [0. 0. 0. 0. 0. 0.]\n",
      "Policy: [0 0 0 0 0 0]\n",
      "Value per step: [0. 0. 0. 0. 0. 0.]\n",
      "Time 1:\n",
      "Values: [10.14464 12.14464 14.14464 19.43808 22.14464 22.     ]\n",
      "Policy: [4 3 2 0 0 0]\n",
      "Value per step: [10.14464 12.14464 14.14464 19.43808 22.14464 22.     ]\n",
      "Time 2:\n",
      "Values: [23.22964746 25.22964746 27.22964746 30.44588483 34.73869619 37.22964746]\n",
      "Policy: [5 4 3 0 0 0]\n",
      "Value per step: [13.08500746 13.08500746 13.08500746 11.00780483 12.59405619 15.22964746]\n",
      "Time 3:\n",
      "Values: [35.82032349 37.82032349 39.82032349 43.50962173 47.65914715 49.82032349]\n",
      "Policy: [5 4 3 0 0 0]\n",
      "Value per step: [12.59067603 12.59067603 12.59067603 13.06373691 12.92045096 12.59067603]\n",
      "Time 4:\n",
      "Values: [48.54531946 50.54531946 52.54531946 56.10514191 60.28953115 62.54531946]\n",
      "Policy: [5 4 3 0 0 0]\n",
      "Value per step: [12.72499597 12.72499597 12.72499597 12.59552017 12.630384   12.72499597]\n",
      "Time 5:\n",
      "Values: [61.23321801 63.23321801 65.23321801 68.82881205 73.00361456 75.23321801]\n",
      "Policy: [5 4 3 0 0 0]\n",
      "Value per step: [12.68789855 12.68789855 12.68789855 12.72367014 12.7140834  12.68789855]\n",
      "Time 6:\n",
      "Values: [73.93136933 75.93136933 77.93136933 81.5170769  85.6945285  87.93136933]\n",
      "Policy: [5 4 3 0 0 0]\n",
      "Value per step: [12.69815132 12.69815132 12.69815132 12.68826485 12.69091394 12.69815132]\n",
      "Time 7:\n",
      "Values: [ 86.62668698  88.62668698  90.62668698  94.21512698  98.39184642\n",
      " 100.62668698]\n",
      "Policy: [5 4 3 0 0 0]\n",
      "Value per step: [12.69531765 12.69531765 12.69531765 12.69805008 12.69731793 12.69531765]\n",
      "Time 8:\n",
      "Values: [ 99.3227878 101.3227878 103.3227878 106.9104726 111.0873944 113.3227878]\n",
      "Policy: [5 4 3 0 0 0]\n",
      "Value per step: [12.69610082 12.69610082 12.69610082 12.69534563 12.69554798 12.69610082]\n",
      "Time 9:\n",
      "Values: [112.01867217 114.01867217 116.01867217 119.60656569 123.78343156\n",
      " 126.01867217]\n",
      "Policy: [5 4 3 0 0 0]\n",
      "Value per step: [12.69588437 12.69588437 12.69588437 12.69609309 12.69603716 12.69588437]\n",
      "Time 10:\n",
      "Values: [124.71461636 126.71461636 128.71461636 132.3024522  136.47933353\n",
      " 138.71461636]\n",
      "Policy: [5 4 3 0 0 0]\n",
      "Value per step: [12.69594419 12.69594419 12.69594419 12.6958865  12.69590196 12.69594419]\n",
      "Iteration 1: delta = 1.1817257923471443\n",
      "V = [10.14464 12.14464 14.14464 19.43808 22.14464 22.     ]\n",
      "Iteration 2: delta = 0.38314500818853947\n",
      "V = [21.70668272 23.70668272 25.70668272 29.34510434 33.47929057 35.70668272]\n",
      "Iteration 3: delta = 0.03214189717638887\n",
      "V = [31.77338421 33.77338421 35.77338421 39.73569014 43.7686385  45.77338421]\n",
      "Iteration 4: delta = 0.008769415902490663\n",
      "V = [40.91596552 42.91596552 44.91596552 48.7987064  52.85310864 54.91596552]\n",
      "Optimal Value Function:\n",
      "[40.91596552 42.91596552 44.91596552 48.7987064  52.85310864 54.91596552]\n",
      "Optimal Policy:\n",
      "[5 4 3 0 0 0]\n",
      "Optimal Value Function:\n",
      "[ 0.          2.          4.          7.58784833 11.76472631 14.        ]\n",
      "Optimal Policy:\n",
      "[5 4 3 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binom\n",
    "from MDP import *\n",
    "\n",
    "# Define parameters.\n",
    "num_of_states = 6  # Possible inventory levels from 0 to 5.\n",
    "num_of_actions = 6  # Possible order quantities from 0 to 5.\n",
    "states = np.arange(num_of_states)\n",
    "actions = np.arange(num_of_actions)\n",
    "B = 5  # Maximum inventory level and maximum demand.\n",
    "K = 4  # Fixed ordering cost\n",
    "c = 2  # Unit ordering cost\n",
    "h = 1  # Holding cost per unit\n",
    "p = 8  # Price per unit sold (revenue)\n",
    "b = 2  # Lost sale cost per unit\n",
    "demand_prob = 0.6  # Probability parameter for binomial distribution\n",
    "\n",
    "# Set the time horizon.\n",
    "horizon = 11\n",
    "\n",
    "# Define transition probabilities and rewards.\n",
    "num_states = num_of_states\n",
    "num_actions = num_of_actions\n",
    "\n",
    "transitions = np.zeros((num_states, num_actions, num_states))\n",
    "rewards = np.zeros((num_states, num_actions))\n",
    "\n",
    "# Precompute demand probabilities.\n",
    "demand_probs = np.array([binom.pmf(k, B, demand_prob) for k in range(B + 1)])\n",
    "\n",
    "for s in states:\n",
    "    for a in actions:\n",
    "        # Compute new inventory level after ordering.\n",
    "        inventory_level = min(B, s + a)\n",
    "        max_possible_sales = min(B, inventory_level)  # Can't sell more than demand or inventory\n",
    "\n",
    "        # Compute the probability of transitioning to each next state.\n",
    "        for next_s in states:\n",
    "            for demand in range(B + 1):\n",
    "                # The next state is determined by the inventory level minus demand, bounded between 0 and B.\n",
    "                next_inventory = max(0, inventory_level - demand)\n",
    "                if next_inventory == next_s:\n",
    "                    prob = demand_probs[demand]\n",
    "                    transitions[s, a, next_s] += prob\n",
    "\n",
    "        # Normalize probabilities to ensure they sum to 1.\n",
    "        transitions[s, a, :] /= transitions[s, a, :].sum()\n",
    "\n",
    "        # Compute expected immediate reward for state s and action a.\n",
    "        # Rewards include revenue from sales minus costs.\n",
    "        ordering_cost = K * (a > 0) + c * a\n",
    "        expected_holding_cost = 0\n",
    "        expected_lost_sale_cost = 0\n",
    "        expected_revenue = 0\n",
    "\n",
    "        for demand in range(B + 1):\n",
    "            prob = demand_probs[demand]\n",
    "            sales = min(inventory_level, demand)\n",
    "            leftover_inventory = inventory_level - sales\n",
    "            unmet_demand = max(0, demand - inventory_level)\n",
    "\n",
    "            holding_cost = h * leftover_inventory\n",
    "            lost_sale_cost = b * unmet_demand\n",
    "            revenue = p * sales\n",
    "\n",
    "            expected_holding_cost += prob * holding_cost\n",
    "            expected_lost_sale_cost += prob * lost_sale_cost\n",
    "            expected_revenue += prob * revenue\n",
    "\n",
    "        total_expected_reward = (\n",
    "            expected_revenue\n",
    "            - ordering_cost\n",
    "            - expected_holding_cost\n",
    "            - expected_lost_sale_cost\n",
    "        )\n",
    "\n",
    "        rewards[s, a] = total_expected_reward\n",
    "\n",
    "# Initialize and solve the MDP.\n",
    "mdp = FiniteHorizonMDP(num_states, num_actions, transitions, rewards, horizon)\n",
    "V, policy, dV = mdp.solve()\n",
    "\n",
    "\n",
    "# Print the results.\n",
    "\n",
    "for t in range(horizon):\n",
    "    print(f\"Time {t}:\")\n",
    "    print(\"Values:\", V[t])\n",
    "    print(\"Policy:\", policy[t])\n",
    "    print(\"Value per step:\", dV[t])\n",
    "\n",
    "\n",
    "ihmdp = InfiniteHorizonMDP(num_states, num_actions, transitions, rewards)\n",
    "V_v, policy_v = ihmdp.value_iteration_discount()\n",
    "\n",
    "# Print the results.\n",
    "print(\"Optimal Value Function:\")\n",
    "print(V_v)\n",
    "print(\"Optimal Policy:\")\n",
    "print(policy_v)\n",
    "\n",
    "V_p, policy_p = ihmdp.policy_iteration()\n",
    "print(\"Optimal Value Function:\")\n",
    "print(V_p)\n",
    "print(\"Optimal Policy:\")\n",
    "print(policy_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.2 (Also applies to 3.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: delta = 15000.000000000005\n",
      "V = [ -87.5  -12.5    0.     0.     0.     0.  -115.5  -24.5    0.     0.\n",
      "    0.     0.  -102.   -18.     0.     0.     0.     0.  -150.   -50.\n",
      "    0.     0.     0.     0.  -150.   -50.     0.     0.     0.     0. ]\n",
      "Iteration 2: delta = 9375.0\n",
      "V = [-156.25      -71.63125   -14.765625   -1.378125    0.          0.\n",
      " -157.05      -56.95      -18.6165     -1.9845      0.          0.\n",
      " -162.2       -69.8       -31.05       -4.05        0.          0.\n",
      " -190.        -80.        -25.        -11.25        0.          0.\n",
      " -243.75     -116.875     -25.3125     -2.8125      0.          0.      ]\n",
      "Iteration 3: delta = 393.1631766912465\n",
      "V = [-1.63125000e+02 -7.96631250e+01 -3.89558531e+01 -1.06289719e+01\n",
      " -1.71694687e+00 -1.11628125e-01 -1.61205000e+02 -6.01950000e+01\n",
      " -3.18616500e+01 -2.21488875e+01 -5.08173750e+00 -4.46512500e-01\n",
      " -1.68220000e+02 -7.49800000e+01 -5.31050000e+01 -2.12962500e+01\n",
      " -6.27750000e+00 -9.11250000e-01 -1.94000000e+02 -8.30000000e+01\n",
      " -2.75000000e+01 -2.61250000e+01 -6.96093750e+00 -6.32812500e-01\n",
      " -2.74375000e+02 -1.61687500e+02 -7.32438281e+01 -2.33528906e+01\n",
      " -3.94242187e+00 -3.10078125e-01]\n",
      "Iteration 4: delta = 34.290807379603194\n",
      "V = [-164.21436125  -80.86817375  -49.40913938  -26.41504711  -12.01179164\n",
      "   -3.19817109 -162.440625    -61.339625    -34.00629     -33.03501375\n",
      "  -17.47083375   -5.30970187 -169.39153125  -76.06753125  -55.88003125\n",
      "  -30.76875     -15.80027344   -5.11755469 -194.67907031  -83.57907031\n",
      "  -28.02907031  -27.89157031  -25.97516406   -7.16153906 -277.53796531\n",
      " -166.26921531  -88.64098102  -40.18114477  -14.32865953   -3.22026891]\n",
      "Iteration 5: delta = 5.464644034442442\n",
      "V = [-168.70016781  -85.36554906  -51.99600684  -34.2929572   -23.1079597\n",
      "  -10.7624796  -166.34986172  -65.23976172  -38.00642822  -37.90930059\n",
      "  -26.51571392  -12.33938702 -175.38453828  -82.05213828  -62.03338828\n",
      "  -32.74195078  -25.84844297  -15.74782341 -197.36614905  -86.25614905\n",
      "  -30.70114905  -30.68739905  -30.49575842  -16.92936877 -280.63215052\n",
      " -169.50527552  -93.32006393  -50.39095189  -27.13934663  -12.39030722]\n",
      "Iteration 6: delta = 3.1662356300790573\n",
      "V = [-175.4754651   -92.14200322  -55.81595427  -39.11778527  -30.66662668\n",
      "  -18.40451424 -176.30802724  -75.19701724  -47.97368389  -47.96397113\n",
      "  -32.72745173  -21.41678602 -184.77488572  -91.44164572  -68.33402797\n",
      "  -35.39912047  -30.12010367  -23.05370998 -205.88789141  -94.77689141\n",
      "  -39.22139141  -39.22001641  -39.20085234  -28.03142616 -287.74944669\n",
      " -176.63675919  -97.40314277  -55.36046218  -35.04415788  -21.77508587]\n",
      "Iteration 7: delta = 1.7093276886186584\n",
      "V = [-184.32265393 -100.98930774  -65.16459275  -48.61448944  -38.52129508\n",
      "  -26.42618768 -183.8791417   -82.7680407   -55.54570737  -55.54473609\n",
      "  -36.75568101  -27.14478731 -195.70577212 -102.37244812  -76.63262056\n",
      "  -43.33855344  -38.30168516  -32.66197345 -215.18636642 -104.07526642\n",
      "  -48.51971642  -48.51957892  -48.51766252  -35.92851197 -295.33900749\n",
      " -184.22773874 -103.24478508  -60.18667805  -40.56599987  -28.92000798]\n",
      "Iteration 8: delta = 0.7124022845742807\n",
      "V = [-190.36257397 -107.02923935  -72.91388909  -56.38335012  -44.33048749\n",
      "  -31.91410109 -193.28369028  -92.17258018  -64.95034684  -64.70157908\n",
      "  -44.43566793  -35.59680972 -203.90623799 -110.57290559  -85.83100339\n",
      "  -52.50153904  -47.49695555  -41.38043345 -222.54664383 -111.43553383\n",
      "  -55.87997883  -55.87996508  -55.87977344  -41.8965555  -303.31746966\n",
      " -192.20634279 -111.90429749  -69.00358891  -49.262445    -37.11073594]\n",
      "Iteration 9: delta = 0.6093818243007887\n",
      "V = [-198.57338615 -115.24005269  -82.15295538  -65.49895911  -52.41884559\n",
      "  -39.84879678 -202.07075913 -100.95964812  -73.73742479  -73.71254801\n",
      "  -53.4665325   -44.53288877 -210.09752375 -116.76419051  -93.37508094\n",
      "  -60.04212874  -55.04158072  -48.26325585 -230.65432673 -119.54321573\n",
      "  -63.98766023  -63.98765885  -63.98763969  -50.23347889 -309.05443795\n",
      " -197.94332526 -118.59079164  -76.47944161  -56.67873678  -43.52671949]\n",
      "Iteration 10: delta = 0.3560375096195494\n",
      "V = [-207.43693851 -124.10360516  -90.98522828  -74.43223442  -61.33503174\n",
      "  -48.72094016 -209.14400618 -108.03289508  -80.81067274  -80.80818507\n",
      "  -61.15806871  -51.96456391 -218.21988337 -124.88655005 -101.42640226\n",
      "  -68.09310647  -63.0930427   -56.34961794 -237.23948021 -126.12836911\n",
      "  -70.57281356  -70.57281342  -70.57281151  -57.53016569 -316.7693609\n",
      " -205.65824963 -126.88052972  -85.28305174  -65.4210605   -51.64439754]\n",
      "Iteration 11: delta = 0.31978011545941154\n",
      "V = [-215.01180137 -131.67846804  -98.23437834  -81.70281953  -68.91313826\n",
      "  -56.3654631  -217.12905677 -116.01794566  -88.79572342  -88.79547466\n",
      "  -69.17332431  -59.96726459 -225.59913746 -132.26580412 -108.15817243\n",
      "  -74.82484279  -69.82483552  -63.3986855  -245.20390581 -134.0927947\n",
      "  -78.53723914  -78.53723913  -78.53723894  -66.00116988 -325.52578223\n",
      " -214.41467111 -135.67966282  -94.1422218   -74.30867004  -60.47466831]\n",
      "Iteration 12: delta = 0.2862449726052577\n",
      "V = [-222.97171827 -139.63838493 -106.14583892  -89.6175571   -76.87354139\n",
      "  -64.33571641 -224.27172263 -123.16061151  -95.93838929  -95.93836441\n",
      "  -76.03343777  -66.94678568 -233.96096664 -140.6276333  -115.99933247\n",
      "  -82.6659995   -77.66599868  -71.49497715 -253.94759206 -142.83648095\n",
      "  -87.2809254   -87.2809254   -87.28092538  -74.82781878 -333.28149501\n",
      " -222.1703839  -143.30366733 -101.63048214  -81.80532703  -68.12374264]\n",
      "Iteration 13: delta = 0.24551005288281236\n",
      "V = [-230.04927894 -146.71594561 -113.36538425  -96.83754348  -83.9550144\n",
      "  -71.38320014 -232.2726517  -131.16154059 -103.93931837 -103.93931588\n",
      "  -83.77649298  -74.79879654 -242.74113357 -149.40780023 -124.6527661\n",
      "  -91.31943281  -86.31943272  -80.21051055 -261.70612758 -150.59501647\n",
      "  -95.03946092  -95.03946092  -95.03946091  -82.48987962 -341.23029427\n",
      " -230.11918316 -151.21909032 -109.51126268  -89.68779397  -76.04495443]\n",
      "Iteration 14: delta = 0.21076399071683283\n",
      "V = [-237.82384478 -154.49051144 -121.28817496 -104.76038962  -91.73345678\n",
      "  -79.12636366 -240.91672466 -139.80561355 -112.58339133 -112.58339108\n",
      "  -92.33888879  -83.39570145 -250.51500501 -157.18167168 -132.50079143\n",
      "  -99.1674581   -94.16745809  -88.02220052 -269.61107175 -158.49996063\n",
      " -102.94440508 -102.94440508 -102.94440508  -90.3586441  -348.36790955\n",
      " -237.25679844 -158.41238377 -116.76508423  -96.94276366  -83.23391923]\n",
      "Iteration 15: delta = 0.18036962471354762\n",
      "V = [-246.33851579 -163.00518245 -129.86011969 -113.33234103 -100.24961838\n",
      "  -87.62890094 -248.81165294 -147.70054183 -120.4783196  -120.47831958\n",
      " -100.25835117  -91.30479824 -258.37428019 -165.04094686 -140.40004371\n",
      " -107.06671038 -102.06671038  -95.90186403 -276.87163449 -165.76052337\n",
      " -110.20496782 -110.20496782 -110.20496782  -97.65988383 -356.05051825\n",
      " -244.93940714 -166.16217297 -124.58763989 -104.76631883  -90.97796696]\n",
      "Iteration 16: delta = 0.15817529343523665\n",
      "V = [-254.30817    -170.97483666 -137.82274961 -121.29497174 -108.21909045\n",
      "  -95.6000432  -256.69284292 -155.58173181 -128.35950959 -128.35950959\n",
      " -108.15962446  -99.19758634 -265.73132347 -172.39799014 -147.72447541\n",
      " -114.39114208 -109.39114208 -103.2422754  -284.56733371 -173.4562226\n",
      " -117.90066705 -117.90066705 -117.90066705 -105.4130934  -364.47106267\n",
      " -253.35995156 -174.61324238 -133.07176064 -113.25087641  -99.42640441]\n",
      "Iteration 17: delta = 0.13813116929252736\n",
      "V = [-262.20864471 -178.87531137 -145.71208359 -129.1843058  -116.11927583\n",
      " -103.50287807 -264.08733215 -162.97622104 -135.75399882 -135.75399882\n",
      " -115.54174031 -106.58492995 -273.44491641 -180.11158307 -155.38304788\n",
      " -122.04971455 -117.04971455 -110.9278079  -292.94049734 -181.82938623\n",
      " -126.27383067 -126.27383067 -126.27383067 -113.81629086 -372.48714515\n",
      " -261.37603404 -182.62945765 -141.08812028 -121.26723894 -107.4426095 ]\n",
      "Iteration 18: delta = 0.12040322921835725\n",
      "V = [-269.64730143 -186.31396809 -153.1560573  -136.62827952 -123.55807065\n",
      " -110.94040838 -271.74376033 -170.63264922 -143.410427   -143.410427\n",
      " -123.17266713 -114.22663109 -281.77915342 -188.44582008 -163.68475239\n",
      " -130.35141906 -125.35141906 -119.24545334 -300.99239829 -189.88128718\n",
      " -134.32573162 -134.32573162 -134.32573162 -121.87130081 -380.40130478\n",
      " -269.29019367 -190.53899975 -148.99266351 -129.17171737 -115.35255144]\n",
      "Iteration 19: delta = 0.10224292321079796\n",
      "V = [-277.26869812 -193.93536479 -160.79124003 -144.26346225 -131.17982543\n",
      " -118.5588845  -279.99528404 -178.88417293 -151.66195071 -151.66195071\n",
      " -131.40729387 -122.4683968  -289.86208607 -196.52875274 -171.7616337\n",
      " -138.42830037 -133.42830037 -127.32529981 -308.91653613 -197.80542502\n",
      " -142.24986946 -142.24986946 -142.24986946 -129.79207626 -387.88649802\n",
      " -276.77538691 -198.02594133 -156.48149785 -136.66057631 -122.83934172]\n",
      "Iteration 20: delta = 0.08744279479433587\n",
      "V = [-285.44842693 -202.1150936  -168.98112964 -152.45335186 -139.35981815\n",
      " -126.73646074 -288.09229823 -186.98118712 -159.7589649  -159.7589649\n",
      " -139.49994972 -130.56289405 -297.79907724 -204.46574391 -179.70104589\n",
      " -146.36771255 -141.36771255 -135.2635257  -316.44706116 -205.33595005\n",
      " -149.78039449 -149.78039449 -149.78039449 -137.32365587 -395.49164585\n",
      " -284.38053474 -205.63699437 -164.09894388 -144.27810537 -130.44988363]\n",
      "Iteration 21: delta = 0.07373466630397427\n",
      "V = [-293.55144733 -210.218114   -177.08743137 -160.55965359 -147.46292379\n",
      " -134.83878599 -296.04640295 -194.93529184 -167.71306962 -167.71306962\n",
      " -147.45468627 -138.51736365 -305.37119801 -212.03786467 -187.27245963\n",
      " -153.9391263  -148.9391263  -142.83528588 -324.04960138 -212.93849027\n",
      " -157.38293472 -157.38293472 -157.38293472 -144.93099919 -403.61197925\n",
      " -292.50086814 -213.76214178 -172.22930295 -152.40853213 -138.57461437]\n",
      "Iteration 22: delta = 0.06683387522171284\n",
      "V = [-301.52077202 -218.18743868 -185.05675579 -168.52897801 -155.43224846\n",
      " -142.80811073 -303.65639759 -202.54528647 -175.32306425 -175.32306425\n",
      " -155.06443229 -146.12721471 -312.97501907 -219.64168574 -194.87188721\n",
      " -161.53855388 -156.53855388 -150.43686627 -332.12211307 -221.01100196\n",
      " -165.4554464  -165.4554464  -165.4554464  -153.00782077 -411.71610531\n",
      " -300.6049942  -221.86811319 -180.33727212 -160.51652724 -146.68042605]\n",
      "Iteration 23: delta = 0.06621429764612194\n",
      "V = [-309.16657044 -225.83323711 -192.70268341 -176.17490563 -163.07805024\n",
      " -150.45388178 -311.2588194  -210.14770829 -182.92548607 -182.92548607\n",
      " -162.66489172 -153.72850325 -321.0045406  -227.67120727 -202.89709048\n",
      " -169.56375715 -164.56375715 -158.46418549 -340.22459475 -229.11348364\n",
      " -173.55792808 -173.55792808 -173.55792808 -161.11220142 -419.69891019\n",
      " -308.58779908 -229.85110248 -188.32046108 -168.49971879 -154.66339938]\n",
      "Iteration 24: delta = 0.06452270929463977\n",
      "V = [-316.77230997 -233.43897663 -200.3094558  -183.78167802 -170.6838166\n",
      " -158.05940249 -319.24364888 -218.13253777 -190.91031554 -190.91031554\n",
      " -170.64762061 -161.71211963 -329.10143534 -235.76810201 -210.99184432\n",
      " -177.65851099 -172.65851099 -166.55998837 -348.21951892 -237.10840781\n",
      " -181.55285225 -181.55285225 -181.55285225 -169.1074622  -427.37838463\n",
      " -316.26727351 -237.53064906 -196.00008576 -176.17934448 -162.34293972]\n",
      "Iteration 25: delta = 0.06189094210581113\n",
      "V = [-324.71813867 -241.38480533 -208.25647957 -191.72870179 -178.62967634\n",
      " -166.00497802 -327.32835442 -226.21724331 -198.99502108 -198.99502108\n",
      " -178.73117195 -169.79615863 -337.10685951 -243.77352618 -218.99675146\n",
      " -185.66341812 -180.66341812 -174.56514885 -355.93059764 -244.81948653\n",
      " -189.26393097 -189.26393097 -189.26393097 -176.81863197 -434.99130071\n",
      " -323.8801896  -245.14400169 -203.61391098 -183.79317585 -169.95625456]\n",
      "Iteration 26: delta = 0.058671660202322354\n",
      "V = [-332.78835663 -249.4550233  -216.32741693 -199.79963915 -186.69991299\n",
      " -174.07504358 -335.34146941 -234.23035829 -207.00813607 -207.00813607\n",
      " -186.74394351 -177.80907528 -344.84745472 -251.51412139 -226.73721302\n",
      " -193.40387969 -188.40387969 -182.3056759  -363.55368886 -252.44257775\n",
      " -196.8870222  -196.8870222  -196.8870222  -184.44207957 -442.90361029\n",
      " -331.79249918 -253.05685167 -211.52734601 -191.70661847 -177.86905776]\n",
      "Iteration 27: delta = 0.05496552080945159\n",
      "V = [-340.80700342 -257.47367008 -224.34631416 -207.81853638 -194.71856628\n",
      " -182.09363731 -343.10925525 -241.99814414 -214.77592192 -214.77592192\n",
      " -194.51163607 -185.57680725 -352.48261709 -259.14928376 -234.37204128\n",
      " -201.03870795 -196.03870795 -189.94066787 -371.43752087 -260.32640976\n",
      " -204.77085421 -204.77085421 -204.77085421 -192.32637712 -450.95790025\n",
      " -339.84678914 -261.1114947  -219.58237127 -199.7616487  -185.92367023]\n",
      "Iteration 28: delta = 0.05089335583188378\n",
      "V = [-348.59982687 -265.26649354 -232.13921114 -215.61143336 -202.51139164\n",
      " -189.88644518 -350.75752661 -249.6464155  -222.42419328 -222.42419328\n",
      " -202.15975076 -193.22498814 -360.34200111 -267.00866778 -242.23097291\n",
      " -208.89763958 -203.89763958 -197.79982118 -379.4750553  -268.36394419\n",
      " -212.80838863 -212.80838863 -212.80838863 -200.36423896 -458.9800636\n",
      " -347.86895249 -269.13379746 -227.60482495 -207.78410434 -193.94596093]\n",
      "Iteration 29: delta = 0.04709370172961292\n",
      "V = [-356.26247201 -272.92913868 -239.80194506 -223.27416728 -210.17403909\n",
      " -197.54907152 -358.59559172 -257.48448061 -230.26225839 -230.26225839\n",
      " -209.9976007  -201.06292899 -368.36201518 -275.02868185 -250.25064706\n",
      " -216.91731373 -211.91731373 -205.81966188 -387.49887036 -276.38775925\n",
      " -220.8322037  -220.8322037  -220.8322037  -208.38819767 -466.79580703\n",
      " -355.68469591 -276.94958539 -235.42066106 -215.59994107 -201.761745  ]\n",
      "Iteration 30: delta = 0.044956944305669905\n",
      "V = [-364.08288329 -280.74954996 -247.62247705 -231.09469928 -217.9944535\n",
      " -205.36945722 -366.59725487 -265.48614376 -238.26392153 -238.26392153\n",
      " -217.99909242 -209.06449314 -376.38557942 -283.05224609 -258.27404803\n",
      " -224.9407147  -219.9407147  -213.84314286 -395.33545754 -284.22434643\n",
      " -228.66879087 -228.66879087 -228.66879087 -216.22483461 -474.47374507\n",
      " -363.36263396 -284.62756479 -243.09868523 -223.27796582 -209.43972082]\n",
      "Iteration 31: delta = 0.042506382734869654\n",
      "V = [-372.06633215 -288.73299882 -255.60602709 -239.07824931 -225.97790499\n",
      " -213.35288465 -374.61855406 -273.50744295 -246.28522073 -246.28522073\n",
      " -226.02030247 -217.08574085 -384.2409091  -290.90757576 -266.12931659\n",
      " -232.79598326 -227.79598326 -221.69844136 -403.02929449 -291.91818338\n",
      " -236.36262783 -236.36262783 -236.36262783 -223.91870944 -482.27988601\n",
      " -371.1687749  -292.43376004 -250.90493927 -231.08422063 -217.24591137]\n",
      "Iteration 32: delta = 0.03983742974588582\n",
      "V = [-380.08379998 -296.75046665 -263.62355136 -247.09577358 -233.99537429\n",
      " -221.37034052 -382.49045263 -281.37934152 -254.1571193  -254.1571193\n",
      " -233.89216518 -224.95761871 -391.95092941 -298.61759607 -273.8392967\n",
      " -240.50596337 -235.50596337 -229.40844117 -410.82424968 -299.71313857\n",
      " -244.15758302 -244.15758302 -244.15758302 -231.71371162 -490.24558479\n",
      " -379.13447368 -300.3995063  -258.87073694 -239.05001897 -225.21165353]\n",
      "Iteration 33: delta = 0.03699130205004056\n",
      "V = [-387.97023684 -304.6369035  -271.5100125  -254.98223473 -241.88181177\n",
      " -229.25677223 -390.21664232 -289.10553121 -261.88330898 -261.88330898\n",
      " -241.61833355 -232.68379609 -399.7374334  -306.40410007 -281.62575438\n",
      " -248.29242105 -243.29242105 -237.19492155 -418.77291314 -307.66180203\n",
      " -252.10624647 -252.10624647 -252.10624647 -239.66241755 -498.25786495\n",
      " -387.14675384 -308.41181467 -266.88307586 -247.06235828 -233.22395946]\n",
      "Iteration 34: delta = 0.0340249084525506\n",
      "V = [-395.71244016 -312.37910683 -279.25222934 -262.72445156 -249.62401545\n",
      " -236.9989727  -397.99709362 -296.88598251 -269.66376029 -269.66376029\n",
      " -249.3987623  -240.46423437 -407.66991914 -314.33658581 -289.55819727\n",
      " -256.22486393 -251.22486393 -245.12738543 -426.77885482 -315.66774371\n",
      " -260.11218816 -260.11218816 -260.11218816 -247.66838593 -506.1568815\n",
      " -395.04577039 -316.31084415 -274.78211932 -254.96140192 -241.12298781]\n",
      "Iteration 35: delta = 0.03099146407229298\n",
      "V = [-403.48905495 -320.15572161 -287.0288572  -270.50107942 -257.40063057\n",
      " -244.77558471 -405.91435625 -304.80324514 -277.58102291 -277.58102291\n",
      " -257.31600377 -248.38148477 -415.66853925 -322.33520592 -297.55678907\n",
      " -264.22345574 -259.22345574 -253.1259911  -434.68857451 -323.5774634\n",
      " -268.02190784 -268.02190784 -268.02190784 -255.57811856 -513.91476358\n",
      " -402.80365247 -324.06873312 -282.54001577 -262.71929847 -248.88087619]\n",
      "Iteration 36: delta = 0.02793239885377954\n",
      "V = [-411.39224179 -328.05890846 -294.93205634 -278.40427856 -265.30381774\n",
      " -252.67876895 -413.90482762 -312.79371651 -285.57149428 -285.57149428\n",
      " -265.30646054 -256.37194771 -423.58716063 -330.25382729 -305.47539597\n",
      " -272.14206263 -267.14206263 -261.0446051  -442.46164602 -331.35053491\n",
      " -275.79497936 -275.79497936 -275.79497936 -263.35119686 -521.6895026\n",
      " -410.57839149 -331.84347827 -290.31476755 -270.49405033 -256.65562081]\n",
      "Iteration 37: delta = 0.02661247135309762\n",
      "V = [-419.37397712 -336.04064379 -302.91380049 -286.38602271 -273.2855533\n",
      " -260.66050241 -421.83062735 -320.71951624 -293.49729401 -293.49729401\n",
      " -273.23225242 -264.29774291 -431.37479324 -338.0414599  -313.26302102\n",
      " -279.92968768 -274.92968768 -268.83223385 -450.23622333 -339.12511222\n",
      " -283.56955666 -283.56955666 -283.56955666 -271.12577972 -529.57984231\n",
      " -418.4687312  -339.73382371 -298.20511919 -278.38440206 -264.54596575]\n",
      "Iteration 38: delta = 0.025266358930096676\n",
      "V = [-427.30536633 -343.972033   -310.84519466 -294.31741688 -281.21694264\n",
      " -268.59189057 -429.6320732  -328.52096209 -301.29873986 -301.29873986\n",
      " -281.03369416 -272.09918639 -439.15068107 -345.81734773 -321.0389031\n",
      " -287.70556976 -282.70556976 -276.60811875 -458.11499151 -347.0038804\n",
      " -291.44832484 -291.44832484 -291.44832484 -279.00455301 -537.5524364\n",
      " -426.44132529 -347.70642204 -306.1777221  -286.35700503 -272.51856371]\n",
      "Iteration 39: delta = 0.02372501589580448\n",
      "V = [-435.11980438 -351.78647105 -318.65963534 -302.13185757 -289.03138075\n",
      " -276.40632806 -437.41051419 -336.29940308 -309.07718086 -309.07718086\n",
      " -288.8121322  -279.87762568 -447.01916581 -353.68583248 -328.90738267\n",
      " -295.57404934 -290.57404934 -284.47660085 -466.07820649 -354.96709538\n",
      " -299.41153982 -299.41153982 -299.41153982 -286.96777187 -545.48794515\n",
      " -434.37683404 -355.64193328 -314.11323603 -294.29251899 -280.45407474]\n",
      "Iteration 40: delta = 0.022036166516171574\n",
      "V = [-442.90184355 -359.56851021 -326.44167631 -309.91389853 -296.81341997\n",
      " -284.18836685 -445.26999219 -344.15888108 -316.93665886 -316.93665886\n",
      " -296.67160762 -287.73710219 -454.97291126 -361.63957793 -336.86112411\n",
      " -303.52779077 -298.52779077 -292.43034426 -474.01648791 -362.9053768\n",
      " -307.34982124 -307.34982124 -307.34982124 -294.90605566 -553.31448977\n",
      " -442.20337866 -363.46847924 -321.93978345 -302.11906643 -288.28062058]\n",
      "Iteration 41: delta = 0.020243405347687503\n",
      "V = [-450.75357632 -367.42024299 -334.2934106  -317.76563282 -304.66515278\n",
      " -292.0400993  -453.21430905 -352.10319794 -324.88097572 -324.88097572\n",
      " -304.61592246 -295.68141788 -462.91274122 -369.57940788 -344.80095153\n",
      " -311.4676182  -306.4676182  -300.37017292 -481.85420731 -370.7430962\n",
      " -315.18754064 -315.18754064 -315.18754064 -302.74377636 -561.10097914\n",
      " -449.98986803 -371.25496949 -329.72627465 -309.90555764 -296.06711075]\n",
      "Iteration 42: delta = 0.019055595779949447\n",
      "V = [-458.68863372 -375.35530039 -342.22846921 -325.70069143 -312.60021021\n",
      " -299.97515645 -461.15458653 -360.04347542 -332.8212532  -332.8212532\n",
      " -312.55619862 -303.6216946  -470.76067285 -377.42733951 -352.64888173\n",
      " -319.3155484  -314.3155484  -308.21810382 -489.64582041 -378.5347093\n",
      " -322.97915374 -322.97915374 -322.97915374 -310.53539029 -568.94618728\n",
      " -457.83507617 -379.10017835 -337.57148429 -317.75076729 -303.91231955]\n",
      "Iteration 43: delta = 0.018253659382887363\n",
      "V = [-466.62838851 -383.29505518 -350.1682248  -333.64044702 -320.53996502\n",
      " -307.91491106 -469.0117521  -367.90064098 -340.67841876 -340.67841876\n",
      " -320.41336342 -311.47885972 -478.55791855 -385.22458521 -360.44612654\n",
      " -327.11279321 -322.11279321 -316.01534907 -497.48566964 -386.37455853\n",
      " -330.81900297 -330.81900297 -330.81900297 -318.37524018 -576.87225953\n",
      " -465.76114842 -387.02625117 -345.49755773 -325.67684074 -311.83839232]\n",
      "Iteration 44: delta = 0.01729761944627011\n",
      "V = [-474.4938126  -391.16047927 -358.03364937 -341.50587159 -328.40538912\n",
      " -315.78033505 -476.81498937 -375.70387826 -348.48165604 -348.48165604\n",
      " -328.21660023 -319.28209672 -486.39350801 -393.06017468 -368.28171533\n",
      " -334.948382   -329.948382   -323.85093819 -505.40312005 -394.29200894\n",
      " -338.73645339 -338.73645339 -338.73645339 -326.29269111 -584.81064591\n",
      " -473.6995348  -394.96463794 -353.43594493 -333.61522795 -319.77677906]\n",
      "Iteration 45: delta = 0.01622079918409562\n",
      "V = [-482.30326831 -398.96993498 -365.84310537 -349.31532759 -336.21484484\n",
      " -323.5897907  -484.64734331 -383.5362322  -356.31400997 -356.31400997\n",
      " -336.04895382 -327.11445046 -494.3027728  -400.96943947 -376.19097958\n",
      " -342.85764625 -337.85764625 -331.76020271 -513.33941316 -402.22830205\n",
      " -346.67274649 -346.67274649 -346.67274649 -334.22898458 -592.68336614\n",
      " -481.57225502 -402.83735841 -361.30866565 -341.48794867 -327.6494995 ]\n",
      "Iteration 46: delta = 0.015053893988225058\n",
      "V = [-490.13333225 -406.79999891 -373.67316951 -357.14539174 -344.04490878\n",
      " -331.41985459 -492.54891677 -391.43780565 -364.21558343 -364.21558343\n",
      " -343.95052701 -335.01602376 -502.23636341 -408.90303007 -384.1245698\n",
      " -350.79123647 -345.79123647 -339.69379311 -521.21849087 -410.10737976\n",
      " -354.5518242  -354.5518242  -354.5518242  -342.10806252 -600.49914824\n",
      " -489.38803713 -410.65314066 -369.12444806 -349.30373108 -335.46528175]\n",
      "Iteration 47: delta = 0.01382474209110878\n",
      "V = [-498.02775461 -414.69442128 -381.56759204 -365.03981426 -351.93933115\n",
      " -339.31427692 -500.47930548 -399.36819437 -372.14597215 -372.14597215\n",
      " -351.88091552 -342.94641236 -510.12089261 -416.78755927 -392.00909876\n",
      " -358.67576543 -353.67576543 -347.57832219 -529.04060266 -417.92949155\n",
      " -362.37393599 -362.37393599 -362.37393599 -349.93017444 -608.32778396\n",
      " -497.21667285 -418.48177647 -376.95308398 -357.13236701 -343.29391755]\n",
      "Iteration 48: delta = 0.012606392068914792\n",
      "V = [-505.95454659 -422.62121325 -389.49438413 -372.96660636 -359.86612313\n",
      " -347.24106887 -508.36842052 -407.25730941 -380.03508719 -380.03508719\n",
      " -359.77003044 -350.83552733 -517.94924626 -424.61591293 -399.83745227\n",
      " -366.50411894 -361.50411894 -355.40667577 -536.86858606 -425.75747495\n",
      " -370.20191939 -370.20191939 -370.20191939 -357.75815794 -616.21562762\n",
      " -505.10451651 -426.36962022 -384.84092781 -365.02021084 -351.18176129]\n",
      "Iteration 49: delta = 0.012104692817234943\n",
      "V = [-513.84742926 -430.51409592 -397.38726688 -380.8594891  -367.7590058\n",
      " -355.13395153 -516.20285024 -415.09173913 -387.86951691 -387.86951691\n",
      " -367.60446009 -358.66995701 -525.77726677 -432.44393344 -407.66547268\n",
      " -374.33213935 -369.33213935 -363.23469623 -544.75044377 -433.63933266\n",
      " -378.0837771  -378.0837771  -378.0837771  -365.64001572 -624.13852475\n",
      " -513.02741364 -434.2925174  -392.76382505 -372.94310808 -359.10465846]\n",
      "Iteration 50: delta = 0.011498384782387462\n",
      "V = [-521.68770424 -438.3543709  -405.22754191 -388.69976413 -375.59928078\n",
      " -362.97422649 -524.03151163 -422.92040052 -395.6981783  -395.6981783\n",
      " -375.43312142 -366.49861837 -533.65374082 -440.32040749 -415.54194666\n",
      " -382.20861332 -377.20861332 -371.11117024 -552.66923699 -441.55812588\n",
      " -386.00257033 -386.00257033 -386.00257033 -373.558809   -632.03440885\n",
      " -520.92329774 -442.18840154 -400.65970923 -380.83899226 -367.0005426 ]\n",
      "Iteration 51: delta = 0.010808744932934948\n",
      "V = [-529.51752696 -446.18419362 -413.05736466 -396.52958688 -383.4291035\n",
      " -370.80404921 -531.90320438 -430.79209327 -403.56987105 -403.56987105\n",
      " -383.30481413 -374.3703111  -541.56830218 -448.23496885 -423.45650796\n",
      " -390.12317463 -385.12317463 -379.02573157 -560.56741204 -449.45630093\n",
      " -393.90074537 -393.90074537 -393.90074537 -381.45698408 -639.88024473\n",
      " -528.76913362 -450.03423744 -408.50554516 -388.68482819 -374.8463785 ]\n",
      "Iteration 52: delta = 0.010055627809617699\n",
      "V = [-537.38503268 -454.05169935 -420.92487041 -404.39709263 -391.29660923\n",
      " -378.67155493 -539.81347885 -438.70236774 -411.48014552 -411.48014552\n",
      " -391.21508858 -382.28058555 -549.46811589 -456.13478256 -431.35632163\n",
      " -398.0229883  -393.0229883  -386.92554526 -568.41848186 -457.30737075\n",
      " -401.75181519 -401.75181519 -401.75181519 -389.30805392 -647.71166876\n",
      " -536.60055765 -457.86566149 -416.33696923 -396.51625225 -382.67780255]\n",
      "Iteration 53: delta = 0.009257347990589236\n",
      "V = [-545.29103027 -461.95769693 -428.83086801 -412.30309023 -399.20260682\n",
      " -386.57755251 -547.71433862 -446.60322751 -419.38100529 -419.38100529\n",
      " -399.11594833 -390.18144531 -557.32406012 -463.99072678 -439.21226583\n",
      " -405.8789325  -400.8789325  -394.78148948 -576.25187048 -465.14075937\n",
      " -409.58520381 -409.58520381 -409.58520381 -397.14144256 -655.57556631\n",
      " -544.4644552  -465.72955905 -424.2008668  -404.38014983 -390.54170011]\n",
      "Value:\n",
      "[-545.29103027 -461.95769693 -428.83086801 -412.30309023 -399.20260682\n",
      " -386.57755251 -547.71433862 -446.60322751 -419.38100529 -419.38100529\n",
      " -399.11594833 -390.18144531 -557.32406012 -463.99072678 -439.21226583\n",
      " -405.8789325  -400.8789325  -394.78148948 -576.25187048 -465.14075937\n",
      " -409.58520381 -409.58520381 -409.58520381 -397.14144256 -655.57556631\n",
      " -544.4644552  -465.72955905 -424.2008668  -404.38014983 -390.54170011]\n",
      "\n",
      "Policy:\n",
      "[1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 0 0 1 1 1 1 1 0 1 1 0 0 0 0]\n",
      "Value:\n",
      "[  0.          75.         104.814146   119.689146   131.47958111\n",
      " 142.84212999  -2.15162155  88.84837845 113.34837845 113.34837845\n",
      " 131.58692975 139.62798245 -10.8119527   73.1880473   95.4886622\n",
      " 125.4886622  129.9886622  135.4763609  -27.88335535  72.11664465\n",
      " 122.11664465 122.11664465 122.11664465 133.31602975 -99.28585246\n",
      "   0.71414754  71.57555405 108.95137705 126.79002233 139.2446271 ]\n",
      "\n",
      "Policy:\n",
      "[1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 0 0 1 1 1 1 1 0 1 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binom\n",
    "from MDP import *\n",
    "\n",
    "# Define parameters.\n",
    "M = 5  # Maximum spare parts the repairman can carry\n",
    "N = 5  # Number of towns\n",
    "num_states = (M + 1) * N  # States 0 to M\n",
    "num_actions = 2  # Actions: 0 (do not replenish), 1 (replenish to M)\n",
    "max_demand = 2  # Maximum demand per town\n",
    "\n",
    "# Towns data\n",
    "p = [0.5, 0.25, 0.35, 0.3, 0.5]  # Demand probabilities for towns 1 to 5\n",
    "c = [60, 30, 50, 25, 100]  # Replenishment costs cj for towns 1 to 5\n",
    "K = [200, 200, 200, 200, 200]  # Extra visit costs Kj for towns 1 to 5\n",
    "\n",
    "horizon = 5  # Number of days\n",
    "\n",
    "# Initialize transitions and rewards lists\n",
    "transitions = np.zeros((num_states, num_actions, num_states))\n",
    "rewards = np.zeros((num_states, num_actions))\n",
    "\n",
    "for state in range(num_states):\n",
    "    s = state % (M + 1)  # Spare parts in the repairman's inventory (0 to M)\n",
    "    j = state // (M + 1)  # Current town (0 to N-1)\n",
    "    j_next = (j+1) % N # Next town\n",
    "    pj = p[j_next]\n",
    "    demand_probs = [binom.pmf(k, 2, pj) for k in range(max_demand + 1)]  # Demands 0, 1, 2\n",
    "\n",
    "    for a in range(num_actions):\n",
    "        # Initialize expected cost and transition probabilities\n",
    "        expected_cost = 0.0\n",
    "        trans_probs = np.zeros(num_states)\n",
    "\n",
    "        for d in range(max_demand + 1):  # Demands 0 to 2\n",
    "            prob_d = demand_probs[d]\n",
    "            spare_parts_used = min(s, d)\n",
    "            extra_visit = 1 if d > s else 0\n",
    "\n",
    "            # Spare parts after demand\n",
    "            s_after_demand = s - spare_parts_used\n",
    "\n",
    "            # Spare parts at the start of next day\n",
    "            if a == 1:  # Replenish to full capacity\n",
    "                s_next = M\n",
    "            else:  # Do not replenish\n",
    "                s_next = s_after_demand\n",
    "\n",
    "            # Next state\n",
    "            state_next = s_next + j_next * (M + 1)\n",
    "\n",
    "            # Transition probability\n",
    "            trans_probs[state_next] += prob_d\n",
    "\n",
    "            # Immediate cost\n",
    "            extra_visit_cost = K[j_next] if extra_visit else 0\n",
    "            replenishment_cost = c[j] if a == 1 else 0\n",
    "\n",
    "            expected_cost += prob_d * (extra_visit_cost + replenishment_cost)\n",
    "\n",
    "        # Normalize transition probabilities (ensure they sum to 1)\n",
    "        total_prob = np.sum(trans_probs)\n",
    "        if total_prob > 0:\n",
    "            trans_probs /= total_prob\n",
    "        else:\n",
    "            # This should not happen; if it does, assign equal probabilities\n",
    "            trans_probs[:] = 1.0 / num_states\n",
    "\n",
    "        # Assign the transition probabilities\n",
    "        transitions[state, a, :] = trans_probs\n",
    "\n",
    "        # Assign the expected reward\n",
    "        rewards[state, a] = -expected_cost \n",
    "\n",
    "\n",
    "# Initialize and solve the MDP\n",
    "# mdp = FiniteHorizonMDP(num_states, num_actions, transitions, rewards, horizon)\n",
    "# V, policy, dV = mdp.solve()\n",
    "\n",
    "# # Print the optimal policy\n",
    "# print(\"Value:\")\n",
    "# print(V)\n",
    "# print(\"\\nPolicy:\")\n",
    "# print(policy)\n",
    "# print(\"\\nValue per step:\")\n",
    "# print(dV)\n",
    "\n",
    "ihmdp = InfiniteHorizonMDP(num_states, num_actions, transitions, rewards, 0.9)\n",
    "V_v, policy_v = ihmdp.value_iteration()\n",
    "print(\"Value:\")\n",
    "print(V_v)\n",
    "print(\"\\nPolicy:\")\n",
    "print(policy_v)\n",
    "\n",
    "V_p, policy_p = ihmdp.policy_iteration()\n",
    "print(\"Value:\")\n",
    "print(V_p)\n",
    "print(\"\\nPolicy:\")\n",
    "print(policy_p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: R = 510.0, V = [  0. 510. 510. 510. 510.]\n",
      "Iteration 2: R = 265.0, V = [  0. 265. 265. 265. 265.]\n",
      "Iteration 3: R = 142.5, V = [  0.  142.5 142.5 142.5 142.5]\n",
      "Iteration 4: R = 81.25, V = [ 0.   81.25 81.25 81.25 81.25]\n",
      "Iteration 5: R = 50.625, V = [ 0.    50.625 50.625 50.625 50.625]\n",
      "Iteration 6: R = 35.3125, V = [ 0.         35.3125     35.3125     35.3125     36.33142309]\n",
      "Iteration 7: R = 27.65625, V = [ 0.         27.65625    27.65625    29.35561104 30.33967387]\n",
      "Iteration 8: R = 23.828125, V = [ 0.         24.07661128 25.50777964 27.30439256 27.5380272 ]\n",
      "Iteration 9: R = 25.7421875, V = [ 0.         25.7421875  26.50690099 28.25889714 28.84171193]\n",
      "Iteration 10: R = 26.69921875, V = [ 0.         26.69921875 27.080939   28.80728512 29.59069291]\n",
      "Iteration 11: R = 27.177734375, V = [ 0.         27.17773438 27.36789072 29.08141182 29.96518338]\n",
      "Iteration 12: R = 27.4169921875, V = [ 0.         27.41699219 27.51140284 29.21851143 30.15242862]\n",
      "Iteration 13: R = 27.53662109375, V = [ 0.         27.53662109 27.5831589  29.28706124 30.24605124]\n",
      "Iteration 14: R = 27.596435546875, V = [ 0.         27.59643555 27.61903693 29.32133614 30.29286256]\n",
      "Iteration 15: R = 27.6263427734375, V = [ 0.         27.62634277 27.63697594 29.33847359 30.31626821]\n",
      "Iteration 16: R = 27.64129638671875, V = [ 0.         27.64129639 27.64594545 29.34704232 30.32797104]\n",
      "Iteration 17: R = 27.648773193359375, V = [ 0.         27.64877319 27.65043024 29.35132668 30.33382245]\n",
      "Iteration 18: R = 27.652511596679688, V = [ 0.         27.6525116  27.65267674 29.35346886 30.33674816]\n",
      "Iteration 19: R = 27.654380798339844, V = [ 0.         27.6543808  27.6543808  29.35453995 30.33821101]\n",
      "Iteration 20: R = 27.653446197509766, V = [ 0.         27.6534462  27.6534462  29.35400441 30.33747959]\n",
      "Iteration 21: R = 27.652978897094727, V = [ 0.         27.6529789  27.65298318 29.35373663 30.33711387]\n",
      "Iteration 22: R = 27.653212547302246, V = [ 0.         27.65321255 27.65321255 29.35387052 30.33729673]\n",
      "Iteration 23: R = 27.653095722198486, V = [ 0.         27.65309572 27.65309572 29.35380358 30.3372053 ]\n",
      "Iteration 24: R = 27.653037309646606, V = [ 0.         27.65303731 27.65303731 29.35377011 30.33715959]\n",
      "Iteration 25: R = 27.653008103370667, V = [ 0.         27.6530081  27.6530081  29.35375337 30.33713673]\n",
      "Iteration 26: R = 27.652993500232697, V = [ 0.         27.6529935  27.65299352 29.353745   30.3371253 ]\n",
      "Iteration 27: R = 27.65300080180168, V = [ 0.         27.6530008  27.6530008  29.35374919 30.33713102]\n",
      "Iteration 28: R = 27.65299715101719, V = [ 0.         27.65299715 27.65299715 29.35374709 30.33712816]\n",
      "Iteration 29: R = 27.652995325624943, V = [ 0.         27.65299533 27.65299533 29.35374605 30.33712673]\n",
      "Iteration 30: R = 27.65299441292882, V = [ 0.         27.65299441 27.65299441 29.35374552 30.33712602]\n",
      "R = 27.65299441292882\n",
      "V = [ 0.         27.65299441 27.65299441 29.35374552 30.33712602]\n",
      "policy = [0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from MDP import *\n",
    "\n",
    "# Define parameters.\n",
    "num_states = 5 # States 1 to 4 and 0 is the obsorbing state\n",
    "num_actions = 2  # Actions: 0 (do not exit), 1 (exit)\n",
    "\n",
    "# Reward remaining in the system\n",
    "r = [i for i in range(1, num_states+1)]\n",
    "\n",
    "# Transition probabilities\n",
    "P = [[0.3, 0.4, 0.2, 0.1],\n",
    "     [0.2, 0.3, 0.5, 0.0],\n",
    "     [0.1, 0.0, 0.8, 0.1],\n",
    "     [0.4, 0.0, 0.0, 0.6]]\n",
    "\n",
    "# Initialize transitions and rewards lists\n",
    "transitions = np.zeros((num_states, num_actions, num_states))\n",
    "rewards = np.zeros((num_states, num_actions))\n",
    "\n",
    "\n",
    "def solve(R):\n",
    "    for state in range(num_states):\n",
    "        if state == 0:\n",
    "            # From state 0, any action leads to state 0 with probability 1.0\n",
    "            transitions[state, 0:2, 0] = 1.0\n",
    "            rewards[state, 0:2] = 0\n",
    "        else:\n",
    "            # From states 1 to 4, action 0 leads to states 1 to 4 with probabilities defined by P\n",
    "            transitions[state, 0, 1:5] = P[state-1]\n",
    "            rewards[state, 0] = r[state-1]\n",
    "            # From states 1 to 4, action 1 leads to state 0 with probability 1.0\n",
    "            transitions[state, 1, 0] = 1.0\n",
    "            rewards[state, 1] = R\n",
    "\n",
    "    mdp = InfiniteHorizonMDP(num_states, num_actions, transitions, rewards, discount_factor=0.9)\n",
    "    V, policy = mdp.value_iteration_discount(silence=True)\n",
    "    return V, policy\n",
    "\n",
    "# Find the minimum R that makes the agent exit the system at state 2\n",
    "Rh = 1000\n",
    "Rl = 20\n",
    "iteration = 0\n",
    "# Bisection method\n",
    "while abs(Rh - Rl) > 1e-6:\n",
    "    iteration += 1\n",
    "    R = (Rh + Rl) / 2\n",
    "    V, policy = solve(R)\n",
    "    print(f\"Iteration {iteration}: R = {R}, V = {V}\")\n",
    "    if policy[2] == 1:\n",
    "        Rh = R\n",
    "    else:\n",
    "        Rl = R\n",
    "\n",
    "print(f\"R = {R}\")\n",
    "print(f\"V = {V}\")\n",
    "print(f\"policy = {policy}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: delta = 497.5124378109453\n",
      "V = [   -2.    -2.    -2.    -2.    -2. -1002.]\n",
      "Iteration 2: delta = 352.2388059701493\n",
      "V = [   -4.    -4.    -4.    -4.  -604. -1712.]\n",
      "Iteration 3: delta = 336.1194029850744\n",
      "V = [   -6.     -6.     -6.   -366.  -1098.8 -2389.6]\n",
      "Iteration 4: delta = 308.8358208955223\n",
      "V = [   -8.      -8.    -224.    -707.68 -1663.44 -3012.36]\n",
      "Iteration 5: delta = 300.1611940298506\n",
      "V = [  -10.     -139.6    -459.408 -1146.032 -2196.064 -3617.684]\n",
      "Iteration 6: delta = 6.31508085746521\n",
      "V = [  -89.76    -302.6048  -785.44   -1580.064  -2744.0264 -4201.198 ]\n",
      "Iteration 7: delta = 3.4162218517744116\n",
      "V = [ -219.46688  -538.45248 -1127.36384 -2050.05424 -3279.14064 -4774.04652]\n",
      "Iteration 8: delta = 1.9034864904776265\n",
      "V = [ -412.85824   -806.103616 -1514.304672 -2520.69896  -3817.358248\n",
      " -5335.574756]\n",
      "Iteration 9: delta = 1.33044004527173\n",
      "V = [ -650.8054656 -1123.0506368 -1915.680928  -3006.7762464 -4349.2903664\n",
      " -5890.1098036]\n",
      "Iteration 10: delta = 0.9195743285124421\n",
      "V = [ -936.15256832 -1466.95526016 -2342.54903168 -3494.95612288\n",
      " -4881.02779272 -6437.86397244]\n",
      "Iteration 11: delta = 0.6941446218735191\n",
      "V = [-1256.63418342 -1843.07071552 -2781.31515494 -3990.87699742\n",
      " -5409.3079996  -6980.81311852]\n",
      "Iteration 12: delta = 0.5219022335896581\n",
      "V = [-1610.49610268 -2240.08641955 -3235.5789286  -4489.06704599\n",
      " -5936.6817703  -7519.36158285]\n",
      "Iteration 13: delta = 0.40931154164266237\n",
      "V = [-1990.2502928  -2658.50482992 -3699.02404632 -4991.58944536\n",
      " -6462.00524053 -8054.55763908]\n",
      "Iteration 14: delta = 0.3208275878045542\n",
      "V = [-2393.20301507 -3092.33999862 -4172.40752082 -5496.06930275\n",
      " -6986.41194111 -8586.79191952]\n",
      "Iteration 15: delta = 0.2571905693335932\n",
      "V = [-2814.6852052  -3540.63941688 -4652.58433332 -6003.17635119\n",
      " -7509.53713665 -9116.677926  ]\n",
      "Iteration 16: delta = 0.20632733397064085\n",
      "V = [-3252.25773221 -4000.02010324 -5139.35606911 -6511.8152171\n",
      " -8031.91337462 -9644.53568919]\n",
      "Iteration 17: delta = 0.16765330533531508\n",
      "V = [ -3702.91515483  -4469.29297145  -5631.03076815  -7022.13636721\n",
      "  -8553.45731611 -10170.74899482]\n",
      "Iteration 18: delta = 0.13638112297886876\n",
      "V = [ -4164.7418448   -4946.42230448  -6127.17278858  -7533.59725683\n",
      "  -9074.43603867 -10695.56149121]\n",
      "Iteration 19: delta = 0.11178778220676677\n",
      "V = [ -4635.75012061  -5430.36845704  -6626.8023243   -8046.17318546\n",
      "  -9594.85967564 -11219.22385544]\n",
      "Iteration 20: delta = 0.09173242888086953\n",
      "V = [ -5114.52112247  -5919.84327647  -7129.49468082  -8559.57382122\n",
      " -10114.87223647 -11741.9146015 ]\n",
      "Iteration 21: delta = 0.07562602864315279\n",
      "V = [ -5599.71441487  -6414.03747288  -7634.64674375  -9073.72912825\n",
      " -10634.50813091 -12263.80189199]\n",
      "Iteration 22: delta = 0.06240888207305795\n",
      "V = [ -6090.30824967  -6912.106118    -8141.91339319  -9588.4718145\n",
      " -11153.85068676 -12785.01376367]\n",
      "Iteration 23: delta = 0.051652067289211206\n",
      "V = [ -6585.38697067  -7413.45112261  -8650.90626342 -10103.73161146\n",
      " -11672.93487123 -13305.6648406 ]\n",
      "Iteration 24: delta = 0.042783567355826585\n",
      "V = [ -7084.22546184  -7917.50496151  -9161.36493    -10619.40596291\n",
      " -12191.81187492 -13825.84584979]\n",
      "Iteration 25: delta = 0.03550378381449328\n",
      "V = [ -7586.19316164  -8423.8370927   -9673.0315592  -11135.43720024\n",
      " -12710.51048624 -14345.63565733]\n",
      "Iteration 26: delta = 0.029481168028743697\n",
      "V = [ -8090.77952028  -8932.06059328 -10185.71660388 -11651.75947953\n",
      " -13229.06360309 -14865.098106  ]\n",
      "Iteration 27: delta = 0.024509725257529175\n",
      "V = [ -8597.54816408  -9441.86987774 -10699.24552609 -12168.32909097\n",
      " -13747.49306777 -15384.28775513]\n",
      "Iteration 28: delta = 0.02038636229563923\n",
      "V = [ -9106.14119228  -9952.99875265 -11213.48297051 -12685.10240758\n",
      " -14265.82068714 -15903.24934892]\n",
      "Iteration 29: delta = 0.016970101666489348\n",
      "V = [ -9616.2557285  -10465.23201526 -11728.3093674  -13202.0475442\n",
      " -14784.06240034 -16422.02075039]\n",
      "Iteration 30: delta = 0.01413137012136587\n",
      "V = [-10127.64150055 -10978.38554051 -12243.62906784 -13719.13500484\n",
      " -15302.23295353 -16940.63324537]\n",
      "Iteration 31: delta = 0.011773661500731229\n",
      "V = [-10640.08792453 -11492.30844492 -12759.35957184 -14236.34199295\n",
      " -15820.34374403 -17459.11315782]\n",
      "Iteration 32: delta = 0.00981190038236173\n",
      "V = [-11153.42023676 -12006.87296496 -13275.43368643 -14753.64831727\n",
      " -16338.40486698 -17977.48233368]\n",
      "Value:\n",
      "[-11153.42023676 -12006.87296496 -13275.43368643 -14753.64831727\n",
      " -16338.40486698 -17977.48233368]\n",
      "\n",
      "Policy:\n",
      "[0 4 4 4 4 4]\n",
      "\n",
      "Tau:\n",
      "[[0.1        0.1        0.1        0.1        0.1       ]\n",
      " [0.09090909 0.08333333 0.07692308 0.07142857 0.06666667]\n",
      " [0.09090909 0.08333333 0.07692308 0.07142857 0.06666667]\n",
      " [0.09090909 0.08333333 0.07692308 0.07142857 0.06666667]\n",
      " [0.09090909 0.08333333 0.07692308 0.07142857 0.06666667]\n",
      " [0.09090909 0.08333333 0.07692308 0.07142857 0.06666667]]\n",
      "\n",
      " Rewards: [[ -0.2         -0.4         -0.6         -0.8         -1.        ]\n",
      " [ -0.18181818  -0.33333333  -0.46153846  -0.57142857  -0.66666667]\n",
      " [ -0.18181818  -0.33333333  -0.46153846  -0.57142857  -0.66666667]\n",
      " [ -0.18181818  -0.33333333  -0.46153846  -0.57142857  -0.66666667]\n",
      " [ -0.18181818  -0.33333333  -0.46153846  -0.57142857  -0.66666667]\n",
      " [-91.09090909 -83.66666667 -77.38461538 -72.         -67.33333333]]\n",
      "\n",
      " Speed: [1 2 3 4 5]\n",
      "\n",
      " Operation Cost: [ 2  4  6  8 10]\n",
      "\n",
      " Action: [[0.         1.         0.         0.         0.         0.        ]\n",
      " [0.09090909 0.         0.90909091 0.         0.         0.        ]\n",
      " [0.         0.09090909 0.         0.90909091 0.         0.        ]\n",
      " [0.         0.         0.09090909 0.         0.90909091 0.        ]\n",
      " [0.         0.         0.         0.09090909 0.         0.90909091]\n",
      " [0.         0.         0.         0.         0.09090909 0.90909091]]\n",
      "\n",
      " Action: [[0.         1.         0.         0.         0.         0.        ]\n",
      " [0.16666667 0.         0.83333333 0.         0.         0.        ]\n",
      " [0.         0.16666667 0.         0.83333333 0.         0.        ]\n",
      " [0.         0.         0.16666667 0.         0.83333333 0.        ]\n",
      " [0.         0.         0.         0.16666667 0.         0.83333333]\n",
      " [0.         0.         0.         0.         0.16666667 0.83333333]]\n",
      "\n",
      " Action: [[0.         1.         0.         0.         0.         0.        ]\n",
      " [0.23076923 0.         0.76923077 0.         0.         0.        ]\n",
      " [0.         0.23076923 0.         0.76923077 0.         0.        ]\n",
      " [0.         0.         0.23076923 0.         0.76923077 0.        ]\n",
      " [0.         0.         0.         0.23076923 0.         0.76923077]\n",
      " [0.         0.         0.         0.         0.23076923 0.76923077]]\n",
      "\n",
      " Action: [[0.         1.         0.         0.         0.         0.        ]\n",
      " [0.28571429 0.         0.71428571 0.         0.         0.        ]\n",
      " [0.         0.28571429 0.         0.71428571 0.         0.        ]\n",
      " [0.         0.         0.28571429 0.         0.71428571 0.        ]\n",
      " [0.         0.         0.         0.28571429 0.         0.71428571]\n",
      " [0.         0.         0.         0.         0.28571429 0.71428571]]\n",
      "\n",
      " Action: [[0.         1.         0.         0.         0.         0.        ]\n",
      " [0.33333333 0.         0.66666667 0.         0.         0.        ]\n",
      " [0.         0.33333333 0.         0.66666667 0.         0.        ]\n",
      " [0.         0.         0.33333333 0.         0.66666667 0.        ]\n",
      " [0.         0.         0.         0.33333333 0.         0.66666667]\n",
      " [0.         0.         0.         0.         0.33333333 0.66666667]]\n",
      "\n",
      " Average Reward: 518.3691758631721\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from MDP import *\n",
    "\n",
    "# Define states and actions.\n",
    "B = 5\n",
    "num_states = B+1 # Queue length B\n",
    "num_actions = 5 # Number of speeds K\n",
    "\n",
    "# Data\n",
    "speed = np.arange(1, num_actions+1)\n",
    "lambd = 10\n",
    "mu = 1\n",
    "operation_cost = speed * 2\n",
    "lost_cost = 100\n",
    "\n",
    "# Initialize transitions and rewards lists\n",
    "transitions = np.zeros((num_states, num_actions, num_states))\n",
    "rewards = np.zeros((num_states, num_actions))\n",
    "sojourntime = np.zeros((num_states, num_actions))\n",
    "\n",
    "for s in range(num_states):\n",
    "    for a in range(num_actions):\n",
    "        # Compute the probability of transitioning to each next state.\n",
    "        if 1 <= s < num_states - 1:\n",
    "            transitions[s, a, s+1] = lambd/(lambd + mu * speed[a])\n",
    "            transitions[s, a, s-1] = mu * speed[a]/(lambd + mu * speed[a])\n",
    "            sojourntime[s, a] = 1/(lambd + mu * speed[a])\n",
    "        elif s == 0:\n",
    "            transitions[s, a, s+1] = 1\n",
    "            sojourntime[s, a] = 1/lambd\n",
    "        else:\n",
    "            transitions[s, a, s] = lambd/(lambd + mu * speed[a])\n",
    "            transitions[s, a, s-1] = mu * speed[a]/(lambd + mu * speed[a])\n",
    "            sojourntime[s, a] = 1/(lambd + mu * speed[a])\n",
    "\n",
    "        \n",
    "\n",
    "        rewards[s, a] = -operation_cost[a] * sojourntime[s, a] - lost_cost * lambd * (s == B) * sojourntime[s, a]\n",
    "\n",
    "\n",
    "# Initialize and solve the MDP.\n",
    "tau = min(sojourntime.flatten()) * 0.9\n",
    "smdp = SemiMDP(num_states, num_actions, transitions, sojourntime, rewards, tau=tau)\n",
    "V, policy, avg_reward = smdp.value_iteration()\n",
    "print(\"Value:\")\n",
    "print(V)\n",
    "print(\"\\nPolicy:\")\n",
    "print(policy)\n",
    "print(\"\\nTau:\")\n",
    "print(sojourntime)\n",
    "print(f\"\\n Rewards: {rewards}\")\n",
    "print(f\"\\n Speed: {speed}\")\n",
    "print(f\"\\n Operation Cost: {operation_cost}\")\n",
    "for a in range(num_actions):\n",
    "    print(f\"\\n Action: {transitions[:, a, :]}\")  \n",
    "\n",
    "print(f\"\\n Average Reward: {avg_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: delta = 19800.0\n",
      "V = [  0.   0. 198. 198. 196. 196. 194. 194. 192. 192.]\n",
      "Iteration 2: delta = 19690.000000000004\n",
      "V = [  0.    0.  306.9 306.9 392.9 392.9 388.9 388.9 384.9 384.9]\n",
      "Iteration 3: delta = 19580.000000000007\n",
      "V = [  0.     38.105 366.795 366.795 550.2   550.2   584.7   584.7   578.7\n",
      " 578.7  ]\n",
      "Iteration 4: delta = 19470.000000000004\n",
      "V = [  0.       86.0155  399.73725 399.73725 663.66775 663.66775 763.175\n",
      " 763.175   773.4     773.4    ]\n",
      "Iteration 5: delta = 9.337946532309047\n",
      "V = [ 18.5887375 127.1902875 417.8554875 475.3311875 740.899025  740.899025\n",
      " 912.3967375 912.3967375 960.79875   960.79875  ]\n",
      "Iteration 6: delta = 8.281867090786033\n",
      "V = [  72.9935375   183.8536925   436.18545     536.17330938  791.52943313\n",
      "  794.56746875 1029.22276688 1029.22276688 1131.01784438 1131.01784438]\n",
      "Iteration 7: delta = 3.0493387206090468\n",
      "V = [ 131.31150459  242.39752009  481.90806756  591.9068535   827.62464072\n",
      "  879.88498119 1116.26076669 1116.26076669 1277.2100595  1277.2100595 ]\n",
      "Iteration 8: delta = 1.9572227213691975\n",
      "V = [ 188.56811858  299.67672013  551.21793233  662.21781093  868.0521828\n",
      "  952.6639272  1180.37451    1180.37451    1396.78287773 1396.78287773]\n",
      "Iteration 9: delta = 0.7708798611253284\n",
      "V = [ 251.70935083  362.82021099  616.67508453  727.77507239  921.47677009\n",
      " 1020.43293714 1233.82946276 1269.28851322 1491.39911225 1491.39911225]\n",
      "Iteration 10: delta = 0.5336348839695854\n",
      "V = [ 315.9388126   427.04989862  682.13142511  793.2414239   986.82629053\n",
      " 1096.72190724 1287.27075106 1351.25327355 1567.49276998 1567.49276998]\n",
      "Iteration 11: delta = 0.30553762968947634\n",
      "V = [ 380.72497639  491.83608499  751.91045515  863.02145503 1059.7052429\n",
      " 1170.69480457 1346.07074382 1428.0219321  1633.39286147 1633.39286147]\n",
      "Iteration 12: delta = 0.1696427497171923\n",
      "V = [ 447.75839065  558.86950151  821.32994582  932.44104581 1132.9400485\n",
      " 1244.03900467 1411.20626841 1498.64164293 1696.09790853 1696.09790853]\n",
      "Iteration 13: delta = 0.10270288256375783\n",
      "V = [ 515.86558536  626.97669644  891.44182236 1002.55293236 1203.28121478\n",
      " 1314.3911104  1479.98646945 1566.92577523 1759.89667047 1759.89667047]\n",
      "Iteration 14: delta = 0.05211513273240081\n",
      "V = [ 584.8748915   695.98600261  960.75969531 1071.87080631 1272.59353989\n",
      " 1383.70452945 1549.46910485 1634.12207892 1825.93708001 1825.93708001]\n",
      "Iteration 15: delta = 0.026872787234663346\n",
      "V = [ 654.02305316  765.13416427 1029.93670896 1141.04782006 1340.95615234\n",
      " 1452.0672513  1618.87510062 1701.75093215 1893.52649119 1893.52649119]\n",
      "Iteration 16: delta = 0.01795107833141054\n",
      "V = [ 723.18419827  834.29530938 1098.7343079  1209.84541901 1409.35505373\n",
      " 1520.46616362 1687.81157389 1769.69227733 1961.93336543 1961.93336543]\n",
      "Iteration 17: delta = 0.009373137820865114\n",
      "V = [ 792.1817476   903.29285871 1167.51609364 1278.62720475 1477.72746873\n",
      " 1588.83857972 1756.50613982 1838.04901581 2030.57855924 2030.57855924]\n",
      "\n",
      "States:\n",
      "[(0, 0), (0, 1), (1, 0), (1, 1), (2, 0), (2, 1), (3, 0), (3, 1), (4, 0), (4, 1)]\n",
      "\n",
      " Rewards: [[   0. -100.]\n",
      " [ -50.    0.]\n",
      " [ 198.   -1.]\n",
      " [  49.  198.]\n",
      " [ 196.   -2.]\n",
      " [  48.  196.]\n",
      " [ 194.   -3.]\n",
      " [  47.  194.]\n",
      " [ 192.   -4.]\n",
      " [  46.  192.]]\n",
      "\n",
      " Action: [[1.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.5 0.  0.5 0.  0.  0.  0.  0.  0. ]\n",
      " [1.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.5 0.  0.  0.  0.5 0.  0.  0.  0. ]\n",
      " [0.  0.  1.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.5 0.  0.  0.  0.5 0.  0. ]\n",
      " [0.  0.  0.  0.  1.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.5 0.  0.  0.  0.5]\n",
      " [0.  0.  0.  0.  0.  0.  1.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.5 0.  0.5]]\n",
      "\n",
      " Action: [[0.  0.5 0.  0.5 0.  0.  0.  0.  0.  0. ]\n",
      " [1.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.5 0.  0.  0.  0.5 0.  0.  0.  0. ]\n",
      " [1.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.5 0.  0.  0.  0.5 0.  0. ]\n",
      " [0.  0.  1.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.5 0.  0.  0.  0.5]\n",
      " [0.  0.  0.  0.  1.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.5 0.  0.5]\n",
      " [0.  0.  0.  0.  0.  0.  1.  0.  0.  0. ]]\n",
      "\n",
      " Average Reward: 68.9975493364642\n",
      "\n",
      "Value:\n",
      "[ 792.1817476   903.29285871 1167.51609364 1278.62720475 1477.72746873\n",
      " 1588.83857972 1756.50613982 1838.04901581 2030.57855924 2030.57855924]\n",
      "\n",
      "Policy:\n",
      "[1 0 1 0 1 0 0 0 0 1]\n",
      "\n",
      "Tau:\n",
      "[[1.  0.5]\n",
      " [0.5 1. ]\n",
      " [1.  0.5]\n",
      " [0.5 1. ]\n",
      " [1.  0.5]\n",
      " [0.5 1. ]\n",
      " [1.  0.5]\n",
      " [0.5 1. ]\n",
      " [1.  0.5]\n",
      " [0.5 1. ]]\n",
      "Inventory: 0, Status: 0\n",
      "Optimal Policy: Toggle\n",
      "Inventory: 0, Status: 1\n",
      "Optimal Policy: Keep\n",
      "Inventory: 1, Status: 0\n",
      "Optimal Policy: Toggle\n",
      "Inventory: 1, Status: 1\n",
      "Optimal Policy: Keep\n",
      "Inventory: 2, Status: 0\n",
      "Optimal Policy: Toggle\n",
      "Inventory: 2, Status: 1\n",
      "Optimal Policy: Keep\n",
      "Inventory: 3, Status: 0\n",
      "Optimal Policy: Keep\n",
      "Inventory: 3, Status: 1\n",
      "Optimal Policy: Keep\n",
      "Inventory: 4, Status: 0\n",
      "Optimal Policy: Keep\n",
      "Inventory: 4, Status: 1\n",
      "Optimal Policy: Toggle\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "from MDP import *\n",
    "\n",
    "# Warehouse capacity\n",
    "K = 4\n",
    "\n",
    "# Rates\n",
    "mu = 1      # Manufacturing rate\n",
    "lambd = 1   # Demand arrival rate\n",
    "\n",
    "# Rewards and costs\n",
    "r = 200        # Revenue per satisfied demand\n",
    "h = 2        # Holding cost per item per time unit\n",
    "c = 100        # Operating cost per time unit when machine is on\n",
    "s_cost = 50   # Switching on cost\n",
    "\n",
    "# States: (inventory_level, machine_status)\n",
    "# inventory_level: 0 to K\n",
    "# machine_status: 0 (Off), 1 (On)\n",
    "\n",
    "inventory_levels = list(range(K + 1))\n",
    "machine_statuses = [0, 1]\n",
    "all_states = list(product(inventory_levels, machine_statuses))\n",
    "num_states = len(all_states)\n",
    "\n",
    "# Mapping from state tuple to index and vice versa\n",
    "state_to_index = {state: idx for idx, state in enumerate(all_states)}\n",
    "index_to_state = {idx: state for idx, state in enumerate(all_states)}\n",
    "\n",
    "# Actions:\n",
    "num_actions = 2\n",
    "\n",
    "transitions = np.zeros((num_states, num_actions, num_states))\n",
    "rewards = np.zeros((num_states, num_actions))\n",
    "sojourntime = np.zeros((num_states, num_actions))\n",
    "\n",
    "for s_idx, (inv, status) in enumerate(all_states):\n",
    "    for a in range(num_actions):\n",
    "        # Determine the action effect\n",
    "        if a == 0:\n",
    "            # Action 0: Keep current status\n",
    "            new_status = status\n",
    "            switching_cost = 0.0\n",
    "        else:\n",
    "            # Action 1: Toggle status\n",
    "            new_status = 1 - status\n",
    "            switching_cost = s_cost if new_status == 1 else 0.0\n",
    "\n",
    "        # Define the event rates based on new_status\n",
    "        if new_status == 1:\n",
    "            rate_total = mu + lambd\n",
    "        else:\n",
    "            rate_total = lambd\n",
    "\n",
    "\n",
    "        sojourn_time = 1 / rate_total\n",
    "\n",
    "        sojourntime[s_idx, a] = sojourn_time\n",
    "\n",
    "        holding_cost = h * inv * sojourn_time\n",
    "        operating_cost = c * sojourn_time if new_status == 1 else 0.0\n",
    "\n",
    "        # Initialize expected revenue\n",
    "        expected_revenue = 0.0\n",
    "\n",
    "        # Determine possible events and transitions\n",
    "        if new_status == 1:\n",
    "            # Machine is On: two possible events\n",
    "            # 1. Manufacturing (rate mu)\n",
    "            # 2. Demand arrival (rate lambd)\n",
    "            # Probability of manufacturing: mu / (mu + lambd)\n",
    "            # Probability of demand: lambd / (mu + lambd)\n",
    "\n",
    "            # Manufacturing event\n",
    "            prob_manu = mu / rate_total\n",
    "            # If inventory < K, add one item; else, discard\n",
    "            if inv < K:\n",
    "                next_inv_manu = inv + 1\n",
    "            else:\n",
    "                next_inv_manu = inv  # Item discarded\n",
    "            next_state_manu = (next_inv_manu, new_status)\n",
    "            next_idx_manu = state_to_index[next_state_manu]\n",
    "            transitions[s_idx, a, next_idx_manu] += prob_manu\n",
    "\n",
    "            # Revenue is not affected by manufacturing\n",
    "            reward_manu = - (holding_cost + operating_cost + switching_cost)\n",
    "\n",
    "            # Demand arrival event\n",
    "            prob_demand = lambd / rate_total\n",
    "            if inv > 0:\n",
    "                next_inv_demand = inv - 1\n",
    "                expected_revenue += r  # Revenue from satisfied demand\n",
    "            else:\n",
    "                next_inv_demand = inv  # Demand lost\n",
    "            next_state_demand = (next_inv_demand, new_status)\n",
    "            next_idx_demand = state_to_index[next_state_demand]\n",
    "            transitions[s_idx, a, next_idx_demand] += prob_demand\n",
    "\n",
    "            # Reward for demand event\n",
    "            reward_demand = - (holding_cost + operating_cost + switching_cost) + expected_revenue\n",
    "\n",
    "            # Assign rewards\n",
    "            rewards[s_idx, a] = prob_manu * reward_manu + prob_demand * reward_demand\n",
    "\n",
    "        else:\n",
    "            # Machine is Off: only demand arrival\n",
    "            prob_demand = 1.0\n",
    "            if inv > 0:\n",
    "                next_inv_demand = inv - 1\n",
    "                expected_revenue += r  # Revenue from satisfied demand\n",
    "            else:\n",
    "                next_inv_demand = inv  # Demand lost\n",
    "            next_state_demand = (next_inv_demand, new_status)\n",
    "            next_idx_demand = state_to_index[next_state_demand]\n",
    "            transitions[s_idx, a, next_idx_demand] += prob_demand\n",
    "\n",
    "            # Reward for demand event\n",
    "            reward_demand = - (holding_cost + operating_cost + switching_cost) + expected_revenue\n",
    "\n",
    "            # Assign rewards\n",
    "            rewards[s_idx, a] = prob_demand * reward_demand\n",
    "\n",
    "\n",
    "# Initialize and solve the MDP.\n",
    "tau = min(sojourntime.flatten()) * 0.9\n",
    "smdp = SemiMDP(num_states, num_actions, transitions, sojourntime, rewards, tau=tau)\n",
    "V, policy, avg_reward = smdp.value_iteration()\n",
    "\n",
    "print(\"\\nStates:\")\n",
    "print(all_states)\n",
    "print(f\"\\n Rewards: {rewards}\")\n",
    "for a in range(num_actions):\n",
    "    print(f\"\\n Action: {transitions[:, a, :]}\")  \n",
    "\n",
    "print(f\"\\n Average Reward: {avg_reward}\")\n",
    "print(\"\\nValue:\")\n",
    "print(V)\n",
    "print(\"\\nPolicy:\")\n",
    "print(policy)\n",
    "print(\"\\nTau:\")\n",
    "print(sojourntime)\n",
    "\n",
    "# Print the optimal policy\n",
    "for s_idx, (inv, status) in enumerate(all_states):\n",
    "    print(f\"Inventory: {inv}, Status: {status}\")\n",
    "    action = \"Toggle\" if policy[s_idx] == 1 else \"Keep\"\n",
    "    print(f\"Optimal Policy: {action}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
